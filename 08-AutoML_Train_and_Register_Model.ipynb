{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Model using AutoML\n",
    "Automated machine learning (AutoML) is the process of automating the time consuming, iterative tasks of machine learning model development. It allows data scientists, analysts, and developers to build ML models with high scale, efficiency, and productivity all while sustaining model quality. \n",
    "\n",
    "In short, AutoML is Microsoft's answer to automated Machine Learning.  \n",
    "\n",
    "AutoML takes in Azure Tabular Datasets or Pandas Dataframes for local runs, and Azure Tabular Datasets only for remote runs.  \n",
    "\n",
    "For a list of AutoML algorithms, please consult this page: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Azure Libaries\n",
    "from azureml.core import Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.automl.core.featurization import FeaturizationConfig\n",
    "from azureml.explain.model._internal.explanation_client import ExplanationClient\n",
    "\n",
    "# Import other Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your workspace from the configuration file\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your Datastore by name by filling in the lower case values between double quotes\n",
    "datastore_name = \"<my-datastore-name>\"\n",
    "datastore = Datastore.get(ws, datastore_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your Refined Datasets by name by filling in the lower case values between double quotes\n",
    "dataset_name_test = \"<my-transformed-dataset-name>\"\n",
    "dataset_name_train  = \"<my-transformed-dataset-name>\"\n",
    "\n",
    "# Load Data in as Tabular Datasets\n",
    "testing_data  = Dataset.get_by_name(ws, dataset_name_test, version='latest')\n",
    "training_data = Dataset.get_by_name(ws, dataset_name_train, version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your tabular dataset to pandas data frames\n",
    "testTransformedDF = testing_data.to_pandas_dataframe()\n",
    "trainTransformedDF = training_data.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your Compute Targets for Running AutoML\n",
    "cpu_compute_target = ComputeTarget(ws, '<my-cpu-cluster>')\n",
    "# Retrieve a GPU cluster for Deep Learning Runs\n",
    "gpu_compute_target = ComputeTarget(ws, '<my-gpu-cluster>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we're ready to configure our AutoML run\n",
    "### First, drop all columns not required in your machine learning model and assign your label column\n",
    "Use tabular datasets for remote run.  Tabular data is the only data that will work on remote runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3535dbffc256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop any column that isn't appropriate to add into the model, for example, ID columns, redundant columns or columns with only one value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainTab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WellID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop any column that isn't appropriate to add into the model\n",
    "# For example, ID columns, redundant columns or columns with only one value should be dropped\n",
    "trainTab = training_data.drop_columns(['<MyIdColumn>','<MyRedundantColumn>','<MySingleValueColumn>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, assign the name of the column you are trying to predict to a variable.\n",
    "label = '<MyLabelColumn>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, configure your AutoML settings\n",
    "There are numerous configuration options within AutoML, task, primary metric, featurization and explainability being the most important.<br>\n",
    "Set <b>task</b> to either classification, regression or forecasting depending on the type of problem you are trying to solve.<br>\n",
    "Set <b>Primary Metric</b> to what you are trying to minimize or maximize, like accuracy for classification or rmse for regression problems.<br>\n",
    "<b>Featurization</b> set to Auto automatically one hot encodes categorical values, drops high cardinality categorical columns, imputes missing values across all types of columns, autogenerates numerous datetime features and also creates many features from text data.<br>\n",
    "Set <b>Model Explainability</b> to True to let you obtain a ranked list of features used to generate the AutoML model.\n",
    "\n",
    "For a list and explanation of configurations, click the link below: <br>\n",
    "https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\n",
    "\n",
    "For a list of primary metrics based on problem type, click the following:\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    #\"experiment_timeout_minutes\": 20,  # Use this for testing to limit the autoML run\n",
    "    \"enable_early_stopping\" : True,    # Enable this to end the experiment once results stop improving.  Always use this.\n",
    "    #\"iteration_timeout_minutes\": 5,   # Enable this to limit how long each model takes to run\n",
    "    \"max_concurrent_iterations\": 4,    # Match this value to the max number of nodes in your cluster\n",
    "    #\"max_cores_per_iteration\": -1,     # Only used for DNN \n",
    "    \"n_cross_validations\": 5,         # This is the number of splits to use for cross validation\n",
    "    \"featurization\": 'auto',           # Set to auto to preprocess data\n",
    "    \"preprocess\": True,                # Set to auto to preprocess data\n",
    "    \"enable_dnn\": False,               # Enables Deep Neural Networks for appropriate problems\n",
    "    \"enable_tf\": False,                # Enables Tensorflow algorithms for appropriate problems\n",
    "    \"verbosity\": logging.INFO,         # Enables logging\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = '<my-problem-type>',         # Classification, regression or forecasting\n",
    "                             primary_metric = '<my-metric>',     # Select the metric to be optimized through autoML \n",
    "                             num_classes = 5,                    # Set the number of categories classification\n",
    "                             debug_log = 'automl_errors.log',    # Assigns the debug log name\n",
    "                             compute_target=cpu_compute_target,  # Assign the remote cluster.  If blank, runs locally\n",
    "                             experiment_exit_score = 0.99,       # Threshold to end autoML runs prematurely \n",
    "                             #blacklist_models = ['Prophet'],        # Use to blacklist models\n",
    "                             #whitelist_models = ['KNN'],        # Runs only your selected models\n",
    "                             enable_onnx_compatible_models=False,# Enables/disables enforcing onnx compatible models\n",
    "                             training_data = trainTab,           # Sets the training data\n",
    "                             label_column_name = label,          # Sets the column to predict in your training data\n",
    "                             model_explainability=True,          # Enables/disables model explainability\n",
    "                             enable_voting_ensemble=True,        # Enables/disables voting ensemble algorithm\n",
    "                             enable_stack_ensemble=True,         # Enables/disables stack ensemble algorithm\n",
    "                             **automl_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your Experiment\n",
    "An experiment is a grouping of many runs from a specified script. It always belongs to a workspace. When you submit a run, you provide an experiment name. Information for the run is stored under that experiment. If you submit a run and specify an experiment name that doesn't exist, a new experiment with that newly specified name is automatically created.\n",
    "\n",
    "To learn more about Experiments, click here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for experiment appropriate to the project\n",
    "experiment_name = '<my-experiment-name>'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "# Output a nice table with all of the essential experiment information\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model\n",
    "remote_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Widget to best view Model Results\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare your results to the default model accuracy.  This is the number to beat.  Pick one depending on your Problem.\n",
    "\n",
    "# For Classification problems, the default model accuracy is simply predicting the most common class every time.\n",
    "Default_Model_Accuracy = trainTransformedDF[trainTransformedDF.MyLabelColumn=='<my-most-common-value>'].Label.count()/trainTransformedDF.MyLabelColumn.count()\n",
    "print(Default_Model_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare your results to the default model accuracy.  This is the number to beat.  Pick one depending on your Problem.\n",
    "\n",
    "# For Regression problems, the default model score is rmse if you predict the average.\n",
    "trainTransformedDF['DefaultPrediction'] = np.mean(trainTransformedDF.MyPredictionColumn)\n",
    "trainTransformedDF['SquaredError'] = (trainTransformedDF['MyPredictionColumn'] - trainTransformedDF['DefaultPrediction'])**2\n",
    "Default_Model_RMSE = np.mean(trainTransformedDF.SquaredError)\n",
    "print(Default_Model_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain and Register Model to Machine Learning Work Space\n",
    "Next up is retrieving your model and registering it to your workspace.  Registering your model lets you deploy it, run it in pipelines, and store it for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download your scoring file and your environment file to your local notebook.\n",
    "To deploy models, Azure ML requires a scoring script to make predictions on new data using your model.  It also requires an environment file containing all of the packages required to run your scoring script.  Here, we retrieve both of these from Auto_ML's get_output() function and write them to our local VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Directory to your store your files first\n",
    "inference_folder = os.path.join(os.getcwd(), 'inference')\n",
    "os.makedirs(inference_folder, exist_ok=True)\n",
    "\n",
    "# Specify names for your scoring scrip and environment file\n",
    "script_file_name = 'inference/score.py'\n",
    "environment_file_name = 'inference/AutoML.yml'\n",
    "\n",
    "# Download the files locally\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)\n",
    "best_run.download_file('outputs/conda_env_v_1_0_0.yml', environment_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a meaningful description and tags to your autoML model\n",
    "description = '<my-model-description>'\n",
    "tags = {\"<my-tag-name>\": \"<my-tag-value>\", \"<my-tag-name2>\": \"<my-tag-value2>\"}\n",
    "\n",
    "# Retrieve the model_name from the autoML run\n",
    "model_name = best_run.properties['model_name']\n",
    "\n",
    "# Register your model, set tags and description\n",
    "model = remote_run.register_model(model_name = model_name, description = description, tags = tags)\n",
    "\n",
    "# Print the Model ID\n",
    "print(remote_run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment to register and give it a name\n",
    "autoMLenv = Environment.from_conda_specification(name = \"<my-automl-environment>\",\n",
    "                                             file_path = environment_file_name)\n",
    "\n",
    "# Register the environment to your workspace\n",
    "autoMLenv.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most people can stop here and move on to the next notebook.  \n",
    "If you want to use a pandas dataframe and train an AutoML model locally, follow the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, drop all columns not required in your machine learning model and assign your label column\n",
    "You can use pandas dataframes for local runs.  Tabular data will also work on local runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any column that isn't appropriate to add into the model\n",
    "# For example, ID columns, redundant columns or columns with only one value should be dropped\n",
    "trainDF = trainTransformedDF.drop(['<MyIdColumn>','<MyRedundantColumn>','<MySingleValueColumn>'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, assign the name of the column you are trying to predict to a variable.\n",
    "label = '<MyLabelColumn>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, configure your AutoML settings\n",
    "There are numerous configuration options within AutoML, task, primary metric, featurization and explainability being the most important.<br>\n",
    "Set <b>task</b> to either classification, regression or forecasting depending on the type of problem you are trying to solve.<br>\n",
    "Set <b>Primary Metric</b> to what you are trying to minimize or maximize, like accuracy for classification or rmse for regression problems.<br>\n",
    "<b>Featurization</b> set to Auto automatically one hot encodes categorical values, drops high cardinality categorical columns, imputes missing values across all types of columns, autogenerates numerous datetime features and also creates many features from text data.<br>\n",
    "Set <b>Model Explainability</b> to True to let you obtain a ranked list of features used to generate the AutoML model.\n",
    "\n",
    "For a list and explanation of configurations, click the link below: <br>\n",
    "https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py\n",
    "\n",
    "For a list of primary metrics based on problem type, click the following:\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_local_settings = {\n",
    "    #\"experiment_timeout_minutes\": 20,  # Use this for testing to limit the autoML run\n",
    "    \"enable_early_stopping\" : True,    # Enable this to end the experiment once results stop improving.  Always use this.\n",
    "    #\"iteration_timeout_minutes\": 5,   # Enable this to limit how long each model takes to run\n",
    "    \"max_concurrent_iterations\": 4,    # Match this value to the max number of nodes in your cluster\n",
    "    #\"max_cores_per_iteration\": -1,     # Only used for DNN \n",
    "    \"n_cross_validations\": 5,         # This is the number of splits to use for cross validation\n",
    "    \"featurization\": 'auto',           # Set to auto to preprocess data\n",
    "    \"preprocess\": True,                # Set to auto to preprocess data\n",
    "    \"enable_dnn\": False,               # Enables Deep Neural Networks for appropriate problems\n",
    "    \"enable_tf\": False,                # Enables Tensorflow algorithms for appropriate problems\n",
    "    \"verbosity\": logging.INFO,         # Enables logging\n",
    "}\n",
    "\n",
    "automl_local_config = AutoMLConfig(task = '<my-problem-type>',         # Classification, regression or forecasting\n",
    "                             primary_metric = '<my-metric>',     # Select the metric to be optimized through autoML \n",
    "                             num_classes = 5,                    # Set the number of categories classification\n",
    "                             debug_log = 'automl_errors.log',    # Assigns the debug log name\n",
    "                             #compute_target=cpu_cluster,         # Turn this off for local runs.\n",
    "                             experiment_exit_score = 0.99,       # Threshold to end autoML runs prematurely \n",
    "                             #blacklist_models = ['Prophet'],        # Use to blacklist models\n",
    "                             #whitelist_models = ['KNN'],        # Runs only your selected models\n",
    "                             enable_onnx_compatible_models=False,# Enables/disables enforcing onnx compatible models\n",
    "                             training_data = trainDF,           # Sets the training data\n",
    "                             label_column_name = label,          # Sets the column to predict in your training data\n",
    "                             model_explainability=True,          # Enables/disables model explainability\n",
    "                             enable_voting_ensemble=True,        # Enables/disables voting ensemble algorithm\n",
    "                             enable_stack_ensemble=True,         # Enables/disables stack ensemble algorithm\n",
    "                             **automl_local_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your Experiment\n",
    "An experiment is a grouping of many runs from a specified script. It always belongs to a workspace. When you submit a run, you provide an experiment name. Information for the run is stored under that experiment. If you submit a run and specify an experiment name that doesn't exist, a new experiment with that newly specified name is automatically created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for experiment appropriate to the project\n",
    "local_experiment_name = '<my-experiment-name>'\n",
    "\n",
    "local_experiment=Experiment(ws, local_experiment_name)\n",
    "\n",
    "# Output a nice table with all of the essential experiment information\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Experiment Name'] = local_experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model\n",
    "# Local ones give more detailed information than remote runs.\n",
    "local_run = local_experiment.submit(automl_local_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Widget to best view Model Results\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare your results to the default model accuracy.  This is the number to beat.  Pick one depending on your Problem.\n",
    "\n",
    "# For Classification problems, the default model accuracy is simply predicting the most common class every time.\n",
    "Default_Model_Accuracy = trainTransformedDF[trainTransformedDF.MyLabelColumn=='<my-most-common-value>'].Label.count()/trainTransformedDF.MyLabelColumn.count()\n",
    "print(Default_Model_Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare your results to the default model accuracy.  This is the number to beat.  Pick one depending on your Problem.\n",
    "\n",
    "# For Regression problems, the default model score is rmse if you predict the average.\n",
    "trainTransformedDF['DefaultPrediction'] = np.mean(trainTransformedDF.MyPredictionColumn)\n",
    "trainTransformedDF['SquaredError'] = (trainTransformedDF['MyPredictionColumn'] - trainTransformedDF['DefaultPrediction'])**2\n",
    "Default_Model_RMSE = np.mean(trainTransformedDF.SquaredError)\n",
    "print(Default_Model_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain and Register Model to Machine Learning Work Space\n",
    "Next up is retrieving your model and registering it to your workspace.  Registering your model lets you deploy it, run it in pipelines, and store it for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download your scoring file and your environment file to your local notebook.\n",
    "To deploy models, Azure ML requires a scoring script to make predictions on new data using your model.  It also requires an environment file containing all of the packages required to run your scoring script.  Here, we retrieve both of these from Auto_ML's get_output() function and write them to our local VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_local_run, fitted_local_model = local_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Directory to your store your files first\n",
    "inference_folder = os.path.join(os.getcwd(), 'inference')\n",
    "os.makedirs(inference_folder, exist_ok=True)\n",
    "\n",
    "# Specify names for your scoring scrip and environment file\n",
    "script_file_name_local = 'inference/score_local.py'\n",
    "environment_file_name_local = 'inference/AutoML_local.yml'\n",
    "\n",
    "# Download the files locally\n",
    "best_local_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name_local)\n",
    "best_local_run.download_file('outputs/conda_env_v_1_0_0.yml', environment_file_name_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a meaningful description and tags to your autoML model\n",
    "description = '<my-model-description>'\n",
    "tags = {\"<my-tag-name>\": \"<my-tag-value>\", \"<my-tag-name2>\": \"<my-tag-value2>\"}\n",
    "\n",
    "# Retrieve the model_name from the autoML run\n",
    "model_name_local = best_local_run.properties['model_name']\n",
    "\n",
    "# Register your model, set tags and description\n",
    "model_local = local_run.register_model(model_name = model_name_local, description = description, tags = tags)\n",
    "\n",
    "# Print the Model ID\n",
    "print(local_run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an environment to register and give it a name\n",
    "autoMLenv_local = Environment.from_conda_specification(name = \"<my-automl-environment>\",\n",
    "                                             file_path = environment_file_name_local)\n",
    "\n",
    "# Register the environment to your workspace\n",
    "autoMLenv_local.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
